[TOC]



### 数据库的三个范式

+ 第一范式：每个字段都是原子性的，不能在继续分解。
+ 第二范式：表必须有主键，非主属性必须完全依赖而不能部分依赖主键
+ 第三范式：非主属性必须直接依赖到主键，不能间接的依赖主键
### 数据库分库分表
为什么分库分表：
1. 业务拆分，复杂系统变简单 
2. 数据隔离，将核心业务和非核心业务区分开

分布式ID生成服务：
1.使用Twitter的snowflake,生成一个（完全无序，趋势递增，单调递增）具体业务具体分析

join查询的问题
1. 将join的几个表都改成单表查询，使用代码进行拼装。
2. 提前将join结果写好写到一个表中
3. 使用搜索引擎，将数据库数据导入到ES中进行查询

### B+树（逻辑结构）
1. 叶子节点上所有索引值从小到大顺序排序，双向链表，每一个key执行一条记录
2. 所有的非叶子节点的数据都是荣誉的，每个节点存储的叶子节点的最小值，同层也是双显链表

### 基于B+树的索引可以实现
1. 范围查询：查询范围最大值和最小值，然后顺序遍历
2. 排序：索引天然支持排序，
3. 分页：大偏移量的分页，先查出将offset=1000的位置换算成某个userId

### B+树（物理结构）
1. 每个page的大小16kb，

### 思考
1. 为什么按照主键的递增顺序插入记录？为了避免page split问题

### 非主键索引
1. 结构与主键索引相类似，但是在叶子节点上存储的不是记录的指针而是主键值。
先通过非主键索引找到主键值，在通过主键索引找到记录。所以非主键索引查询两个B+树。

### 事务与锁

1. 事务：一个代码块全执行或全不执行

2. 事务之间的并发关系导致事务的隔离级别

   | 脏读     | 事务a读取一条记录，做修改在提交之前，事务b回滚了他对这条记录的修改，导致a读的是一条脏数据 |      |
   | -------- | ------------------------------------------------------------ | ---- |
   | 不可重读 | 一个事务两次读取同一条记录，结果不用，因为另一个事务正对此条记录进行修改 |      |
   | 幻读     | 同一个事务中，两条select结果不同，因为另外一个表在进行INSERT/Update操作 |      |
   | 丢失更新 | 丢失更新，两个事务同时修改一条记录，事务a覆盖了事务b的修改   |      |

3. 事务的隔离级别

   + 原子性：事务全不执行，或全部执行，执行失败要回滚
   + 一致性：保证了一个事务多次操作的数据中间状态对其他事务不可见，过度状态对于事务开始和结束的状态是不一致的不合理的。
   + 隔离性：事务之间不能互相影响
   + 持久性：提交的事务对数据的修改是永久性

4. 为了解决事务的隔离级别，InnoDB提供乐四种事务隔离级别

   | RU（读未提交）  | 可以读取到未提交的事务修改的数据                             | 什么都没解决                   |
   | --------------- | ------------------------------------------------------------ | ------------------------------ |
   | RC （已提交读） | 只能读取到已提交的事务的修改                                 | 解决了脏读问题                 |
   | RR （可重复读） | 在同一分事务中读取的相同一条数据不会受其他数据影响，数量也不会受其他事务影响 | 解决了脏读、不可重读、丢失更新 |
   | 串行化          | 解决所有问题                                                 | 完全解决所有问题               |

#### 悲观锁和乐观锁

1. 默认的隔离级别没有解决丢失更新的问题，如何解决丢失更新的问题

   + 利用单条语句的原子性（就是能写成一条语句的sql不写成查询出在再修改的形式）

   + 悲观锁：读之前就对该记录进行上锁，其他事务无法读取当前记录

     ```sql
     select xxx for update
     --1、在事务提交之前出现问题容易出现死锁，2、不适合高并发的场景，当前事务之外的事务都会被阻塞
     ```

   + 乐观锁：读不加锁，写的时候会判断记录是不是被修改（相当于数据库层面的CAS）。给表加一个version

     在一个update语句中实现version的修改，version 的比较，值得修改操作。属于原子性操作，所以可以解决丢失更新问题。

     


### 事务的实现原理

##### Redo Log

    1. 在事务修改后会使用write-ahead logging 算法，先写redo log 记录对数据库的修改结果，调用后台线程将该结果存储到物理引擎，如果出现断电等异常问题时，mysql可以使用redo 日志将数据恢复到断电之前的状态，维护事务的持久性。
       2. redo log 记录了提交的和未提交的所有事务的修改，而且一个事务在redolog中可能是不连续的，

```sql
--redolog的异步的刷盘策略：默认每秒刷一次盘，每提交一个事务刷一次盘，不刷盘按照自己的设置决定刷盘频率
--redo log是一个固定大小的文件，循环使用，因为一旦数据刷到磁盘上，redo log就没存在的必要了
```

3. 在redolog中 lsn按照时间顺序上从小到大，记录从进数据库安装开始到当前总的写入得字节数。LSN不从0开始，从8192开始因为innodb维护了一个LOG_START_LSN变量。事务有大有小，所以日志记录是变长的。

4. ![](.\redolog.png)

5. 日志的存储格式

   - 类似binlog的statement格式，记录原始sql 增改删，属于逻辑计法

   - 类似binlog的raw格式，记录每张表的每条记录的修改前的值和修改后的值，属于逻辑计法

   - 记录每个页的字节数据，有哪些部分被修改，如果有多个地方被修改就会有多条物理日志。物理记法

     ```(pageId,offset,len,修改前的值，修改后的值)```

   - redolog使用的是物理加逻辑（physiological logging），先以page记录日志，然后在page内使用逻辑记法（记录page的哪一行被修改了）。单纯的逻辑日志不好恢复，单纯物理物理日志又很大，所以mysql使用的是physiological logging

6. 事务、lsn、logblock的关系

   - 一个事务在logblock上的可能是连续的也可能是不连续的，中间有其他事务的日志。

   - 每个事务产生的lsn在redo log中是一链表的形式连接的

   - 每个事务会有一个单调递增的唯一的ID，由InnoDB分配

     

7. IO写入得原子性

   - 实现事务的原子性，需要考虑计算机是不是支持io的原子性，可以使用checkSum解决在512LogBlock中写入时出现宕机问题（操作系统底层不支持512原子性写的操作，如果支持不需要考虑这个问题），checksum可以判断一个blocklog是否完整，如果不完整就丢弃这个块。
   - Double Write redolog有写入得原子性问题，page的写入也肯定有问题，
   - 两种解决办法： 1. 让计算机支持16kb的原子性写入，2.将page写到一个临时磁盘，写入成功在拷贝到目标位置。
   - redo log的写入方式一块一块的写入。log文件为一组文件，可以理解为一个大文件。
   
8. redoLog 恢复算法：

   - 第一步：在系统中维护两个表，一活跃事务表：当前所有未提交事务的集合 二脏页表：所有未刷磁盘page的集合。每隔一段时间会根据两个表生成checkpoint存到redolog中，恢复时可通过checkpoint判断有哪些事务为提交，那些page的修改未刷盘
   - 第二部：进行redo ，根据page内记录的pageLSN(最后一次修改他的日志的LSN)，redolog的SLN只有>=pageSLN时才会进行修改，修改完成后，所有的脏页都写入到了磁盘，提交的未提交的事务也都写入了磁盘。下一步将是对事务进行回滚。
   - 第三部：进行undo。redolog的每条日志有prevLSN，沿着未提交的事务逆向遍历可以找到为提交事务的第一条记录。根据每个事务的日志生成一个逆向的sql语句执行。
   - 不会出现回滚嵌套问题，因为回滚申城的日志记录了undonxtLSN记录了下一个需要回滚的事务。有此标记的事务不再惊醒会滚。

9. redolog总结

   - 一个事务对应多条redolog，事物的redolog是不连续存储的
   - redolog不保证食物的原子性。而保证了持久性。无论是提交的和未提交的事务都会进入到redolog。
   - 回滚通过checkpoint记录的“”活跃事务表+脏页表“”来实现
   - 无论是未提交的还是提交的事务，对应的page的数据都可能被刷到磁盘中。通过事务回滚未提交的事务。
   - 事务不存在物理回滚。的所有的回滚都是转化为了commit



### 事务的实现原理undo log

#### 事务回滚的场景

1. 人为回滚，事务执行发生异常，客户端调用回滚
2. 宕机回滚，事务执行到一半数据库宕机，重启，需要回滚
3. 人为+宕机。客户端调用回滚，数据库开始回滚，回滚到一般出现宕机，继续回滚
4. 宕机回滚+宕机回滚，宕机回滚中又出现宕机

####  Undo Log （MVCC）

1. 多线程并发的读写问题的三种策略
   - 互斥锁：任何操作都是互斥的
   - 读写锁：除读和读外的任何操作都是互斥的
   - CopyOnWrite：将数据拷贝一分，等写完之后，再把数据对象的指针，一次性赋值回去。读的时候读取原始数据，可以实现读和读的并发，读和写的并发，理论上写和写的并发
2. MVCC就是多版本并发控制，innodb使用了copyOnWrite思想，每个事务修改记录之前，都会把该条记录拷贝出来，拷贝出来的备份就存到undo log内，事务有唯一编号，每次修改就是一个版本，这种方法维护了事务的隔离性，满足前三个隔离级别。



### 各种锁

1. 按照锁的粒度来分：可分为锁表、锁行、锁一个范围
2. 按照锁的模式来份：可分为共享、排他、意向
3. 两个维度叉乘会形成各种锁
4. 共享锁、排他锁、意向锁、记录锁、间隙锁、临建锁、插入意向锁、自增锁

### 具体锁的用途

1. 意向锁，表级别的锁。事务A在加一个行排他锁，事务B想加一个表排他锁，事务B需要进行全行扫表判断哪一行家了排他锁，再确定，是不是能获得表排他锁。效率低下的问题产生了意向锁。表的加一个意向排他锁，代表了接下来要加一个行排他锁，其他事物想加表排他锁的时候就不需要进行遍历了。
2. 自增锁，表级别的锁。 

### 索引

#### Hash索引

+ 基于hash表+链表的数据结构，只有精确匹配索引所有列的时候查询才有效果，hash索引对每一行的所有列进计算一个哈希码。
+ 哈希索引值包含哈希值和行指针，二部存储字段值，不能使用索引中的值来避免读取行
+ 哈希表的数据结构，无法排序
+ 不支持部分列的单独索引查询。因为他是全列进行哈希的
+ 不支持范围查询
+ 查询数据非常快，除非有很多哈希冲突
+ InnoDB不支持用户创建hash索引，他有自适应哈希索引你，如果某些索引值被使用的非常频繁，她会在B-Tree基础上建立一个哈希索引

#### 空间数据索引

#### 全文索引

#### 索引的有点

+ 减少服务器需要扫描的数据量
+ 把那帮助服务器避免排序和临时表
+ 将随机I/O变成顺序I/O

### 索引失效

+ 索引字段必须是独立的列，不允许加入任何聚合函数和表达式

  ```sql
  EXPLAIN SELECT * FROM usermultinfopar WHERE userid + 1 = 123
  ```

  

+ 前缀索引和索引的选择性

  + 索引合并，UNION 、INTERSECTION、组合前两种情况的联合及相交。

+ 选择合适的索引顺序

#### 聚簇索引

+ 
